{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"x3A2XBqYQg-N"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint\n"]},{"cell_type":"markdown","metadata":{"id":"Jw4QHJlfsSF4"},"source":["## Learning Objectives\n"]},{"cell_type":"markdown","source":["At the end of the mini-hackathon you will be able to:\n","* Perform Data preprocessing\n","* Apply different ML algorithms on the **Titanic** dataset\n","* Perform VotingClassifier\n"],"metadata":{"id":"EsSB95vPsoxS"}},{"cell_type":"markdown","metadata":{"id":"Nh70dVHx0G_B"},"source":["## Dataset Description"]},{"cell_type":"markdown","metadata":{"id":"y-GMJTRb0Iyy"},"source":["The sinking of the Titanic is one of the most infamous shipwrecks in history.\n","\n","On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of many passengers and crew.\n","\n","While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n","\n","[ Data Set Link: Kaggle competition](https://www.kaggle.com/competitions/titanic)\n","\n","<br/>\n","\n","### Data Set Characteristics:\n","\n","**PassengerId:** Id of the Passenger\n","\n","**Survived:** Survived or Not information\n","\n","**Pclass:** Socio-economic status (SES)\n","  * 1st = Upper\n","  * 2nd = Middle\n","  * 3rd = Lower\n","\n","**Name:** Surname, First Names of the Passenger\n","\n","**Sex:** Gender of the Passenger\n","\n","**Age:** Age of the Passenger\n","\n","**SibSp:**\tNo. of siblings/spouse of the passenger aboard the Titanic\n","\n","**Parch:**\tNo. of parents/children of the passenger aboard the Titanic\n","\n","**Ticket:**\tTicket number\n","\n","**Fare:** Passenger fare\n","\n","**Cabin:**\tCabin number\n","\n","**Embarked:** Port of Embarkation\n","  * S = Southampton\n","  * C = Cherbourg\n","  * Q = Queenstown\n"]},{"cell_type":"markdown","source":["## Problem Statement\n","\n","Build a predictive model that answers the question: “what sort of people were more likely to survive?” using titanic's passenger data (ie name, age, gender, socio-economic class, etc)."],"metadata":{"id":"KmusUbENKSEt"}},{"cell_type":"code","source":["# @title Download the datasets\n","from IPython import get_ipython\n","\n","ipython = get_ipython()\n","\n","notebook=\"U1_MH1_Data_Munging\" #name of the notebook\n","\n","def setup():\n","    from IPython.display import HTML, display\n","    ipython.magic(\"sx wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/titanic.csv\")\n","    ipython.magic(\"sx wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/test_titanic.csv\")\n","    print(\"Data downloaded successfully\")\n","    return\n","\n","setup()"],"metadata":{"cellView":"form","id":"ViFc50xKK-tY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"id":"RM8x-pMDLQuq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g5fBLdQaJtd4"},"source":["## Exercise 1 - Load and Explore the Data (2 Marks)\n","\n","* Understand different features in the training dataset\n","* Understand the data types of each column\n","* Notice the columns of missing values\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gn6HQH7abkyL"},"source":["#### Import Required Packages"]},{"cell_type":"code","source":[],"metadata":{"id":"4tUzpuurwCyH"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sW9DMblWkhj_"},"source":["# Load the dataset\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"54ktmr8lh8AS"},"source":["# Getting information about the dataset\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zAvxH5MUPWDj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Exercise 02: Split the data into train and test sets (1 Mark)\n","Note: Apply all your data preprocessing steps in the train set first and keep the test set aside."],"metadata":{"id":"eQGya6YLOku-"}},{"cell_type":"code","source":[],"metadata":{"id":"mps-O7zbPPcL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-pMXWDyaspe3"},"source":["## Exercise 03: Data Cleaning and Processing (15 Marks)\n","### 3.1 Working on the \"Cabin\" column (2 Marks)\n","Find unique entries in the Cabin column. We can label all passengers in two categories having a cabin or not. Check the data type(use: type) of each entry of the Cabin. Convert a string data type into '1' i.e. passengers with cabin and others into '0' i.e. passengers without cabin.  Write a function for the above operation and apply it to the cabin column and create another column with the name \" Has_cabin\" containing only 0 or 1 entries.\n","\n","\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"KozjEOo9VS3Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"n9N82uXWWf81"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" ### 3.2 Working on \"SibSp\" & \"Parch\" columns (1 Mark)\n","Combine columns \"SibSp\" & \"Parch\" and create another column that represents the total passengers in one ticket with the name \"family_size\". In each ticket, there might be Siblings/Spouses (SibSp =Number of Siblings/Spouses Aboard) or Parents/Children (Parch=Number of Parents/Children Aboard ) along with the passenger who booked the ticket.\n","\n","  "],"metadata":{"id":"mUm20kyHVTZe"}},{"cell_type":"code","source":[],"metadata":{"id":"n2vHu13tWJx-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lEkyLqqEVX2p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.3 Working on the\"Embarked\" column (2 Marks)\n","The \"embarked\" column represents the port of Embarkation: Cherbourg(C), Queenstown(Q), and  Southampton(S ). Thus, the entries are of three categories in this column. Fill in the missing rows in this column. We can fill it with the most frequent category. Map these categorical string entries into numerical.\n","\n"],"metadata":{"id":"cGPgnKttVYRL"}},{"cell_type":"code","source":[],"metadata":{"id":"IApw-rL1Y1jE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rVTiJ27OVbzB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0TFv47f9Y0yO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.4 Working on the \"Age\" column (2 Marks)\n","find the number of NaN entries in the age column and their row index. Calculate the mean, Standard deviation of the Age column and check the distribution of the age column.We can fill the missing values with randomly generated integer values between (mean+Standard deviation, mean-Standard deviation). Use : np.isnan; np.random.randint; concept of slicing dataframe. Convert the age column as an integer data type.\n","\n"],"metadata":{"id":"dWmjUnN3VcF6"}},{"cell_type":"code","source":[],"metadata":{"id":"gbLqDB1hVf1a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MFrug-3VakhY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"a9a69SMpa6aG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.5 Working on \"sex\" column (1 Mark)\n","Map the Sex column as 'female' : 0, 'male': 1, and convert it into an integer data type.\n","\n"],"metadata":{"id":"doeanDr0VgGV"}},{"cell_type":"code","source":[],"metadata":{"id":"dGN92EsEVlTQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.6  Optional- Working on the \"Name\" column :\n","Fetch titles from the name. We can map these titles with numbers and convert them into an integer. Use: concept of the regular expression.\n","\n","### 3.7 Optional- Working on the \"Fare\" column :\n","We can convert face into categorical entries like Low, Medium, and High.\n","\n"],"metadata":{"id":"__CWnlGhVln2"}},{"cell_type":"code","source":[],"metadata":{"id":"vuuDE0mQVo7v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.8 Drop the columns (1 Mark)\n","\n","Drop the columns: - \"PassengerId\", \"Name\",  \"SibSp\" & \"Parch\", \"Tickets\", \"Cabin\"\n","\n"],"metadata":{"id":"6oJI0bQOVpP4"}},{"cell_type":"code","source":[],"metadata":{"id":"1ZlnDtiiVvif"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YVYnt5p7ccKK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.9 Apply Standard Scalar (1 Mark)"],"metadata":{"id":"S2EfoVojebWn"}},{"cell_type":"code","source":[],"metadata":{"id":"fVWd4PEaeiod"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.10 Create a single function for preprocessing the test set (X_test) and apply it. (4 Marks)\n","#### **Note**: All the pre-processing steps that were applied on the train set before ML Modelling are also applied on the test set before passing through the predict function."],"metadata":{"id":"Kwa6Ua9Qgbi7"}},{"cell_type":"code","source":["## Create a function\n"],"metadata":{"id":"RLFNNM0SgqZ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Applyting above function\n","\n"],"metadata":{"id":"urGx3SRcc0kN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.11 Apply standard Scalar transformation to x_test (1 Mark)"],"metadata":{"id":"jlA3Gnmrc039"}},{"cell_type":"code","source":[],"metadata":{"id":"N0SAb9ccc2Qm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Exercise  4. Apply Multiple ML Algo. along with  Ensemble Technique (Voting classifier) and display the accuracy (7 Marks)\n","#### Expected Accuracy >= 80%  \n"],"metadata":{"id":"zUMFQj-Gc1BO"}},{"cell_type":"code","source":[],"metadata":{"id":"Xd-21QgEc2TV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Exercise  5. Pre-process the test_set (3 Marks)\n","Again we have to apply the same preprocess function and standard scaler on this test set before passing through predict function.\n","\n","#### Understanding the test set:"],"metadata":{"id":"NIf7BgedjLZ1"}},{"cell_type":"code","source":[],"metadata":{"id":"A4ApkkLec2V7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Note: In the initial train set there were no missing entries in the \"Fare\" column. But, now for the submission test set, there is one missing entry in this column.\n","\n","#### There will be a minor change in the preprocess function to address the above issue."],"metadata":{"id":"syRBMp7ilrbe"}},{"cell_type":"code","source":["\n"],"metadata":{"id":"Ppk5Fq0olrGF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hQ4Lsp6znhrG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"P-TVJii2pwiI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n"],"metadata":{"id":"7mVUaw1um9hH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Exercise  6. Prediction for test data (2 Mark)"],"metadata":{"id":"c-zATg3NnlKo"}},{"cell_type":"code","source":[],"metadata":{"id":"bvDpq5EHnkcB"},"execution_count":null,"outputs":[]}]}