{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"uYE7gRUzFgR5"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"cell_type":"markdown","metadata":{"id":"uJSPjgtDcVBa"},"source":["###Not for Grading"]},{"cell_type":"markdown","metadata":{"id":"a3-AYqMRqHOD"},"source":["## Learning Objectives"]},{"cell_type":"markdown","metadata":{"id":"myNyvBNXVgkX"},"source":["At the end of the experiment,  you will be able to :\n","\n","* Understand the intution of Gradient Descent"]},{"cell_type":"markdown","metadata":{"id":"XsuH046p_d1N"},"source":["## Overview\n","\n","In general terms Gradient means slope or slant of a surface. So gradient descent means descending a slope to reach the lowest point on that surface. Gradient Descent aims to minimize the cost function, a function reaches its minimum value when the slope is equal to 0. Gradient descent is an iterative algorithm, that starts from a random point on a function and travels down its slope in steps until it reaches the minimum point of that function."]},{"cell_type":"markdown","metadata":{"id":"jHSeCQcxJRJr"},"source":["## Setup Steps"]},{"cell_type":"code","metadata":{"id":"2hxRMCMwJRJr"},"source":["#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n","Id = \"aiml_pg_25\" #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_nUtfFS0JRJr"},"source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"4521452411\" #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"r1NlgkaOJRJs"},"source":["#@title Run this cell to complete the setup for this Notebook\n","from IPython import get_ipython\n","\n","ipython = get_ipython()\n","\n","notebook= \"Demo_Gradient_Descent\" #name of the notebook\n","Answer = \"Ungraded\"\n","def setup():\n","#  ipython.magic(\"sx pip3 install torch\")\n","    from IPython.display import HTML, display\n","    ipython.magic(\"sx wget -qq https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Penguin.csv\")\n","    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n","    print(\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","\n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","\n","    import requests, json, base64, datetime\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:\n","        print(r[\"err\"])\n","        return None\n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getComplexity() and getAdditional() and getConcepts() and getComments():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n","              \"concepts\" : Concepts, \"record_id\" : submission_id,\n","              \"id\" : Id, \"file_hash\" : file_hash,\n","              \"feedback_experiments_input\" : Comments, \"notebook\" : notebook}\n","\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","      if \"err\" in r:\n","        print(r[\"err\"])\n","        return None\n","      else:\n","        print(\"Your submission is successful.\")\n","        print(\"Ref Id:\", submission_id)\n","        print(\"Date of submission: \", r[\"date\"])\n","        print(\"Time of submission: \", r[\"time\"])\n","        print(\"View your submissions: https://learn-iiith.talentsprint.com/notebook_submissions\")\n","        # print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n","      return submission_id\n","    else: submission_id\n","\n","\n","def getAdditional():\n","  try:\n","    if not Additional:\n","      raise NameError\n","    else:\n","      return Additional\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","def getComments():\n","  try:\n","    if not Comments:\n","      raise NameError\n","    else:\n","      return Comments\n","  except NameError:\n","    print (\"Please answer Comments Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    if not Complexity:\n","      raise NameError\n","    else:\n","      return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","\n","def getConcepts():\n","  try:\n","    if not Concepts:\n","      raise NameError\n","    else:\n","      return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","def getId():\n","  try:\n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup\n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","\n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UQmzuXIChorp"},"source":["## Import required packages"]},{"cell_type":"code","metadata":{"id":"238GaEpo0MlR"},"source":["import matplotlib.pyplot as plt\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GuYgUJJy6GeU"},"source":["### Intution behind Gradient Descent\n","\n","Mathematical concepts before understanding the gradient descent\n","\n","* Let's take a function,  $f(x) = x^{2} - x + 3$\n","\n","* Task to find the minimum value of the function. It means that find the value of X where the value of Y is minimum."]},{"cell_type":"code","metadata":{"id":"Bufkr_n2yrKe"},"source":["# Keep all the given values of x into the function and see the output values of y.\n","def func(x):\n","    return  x**2 -x + 3\n","\n","X = np.array([-6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7]) # Input values\n","Y = func(X) # Call the function to get the y values\n","\n","print(\"X values: \" , X)\n","print(\"f(x) values: \\n\", Y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-RnaLCsM1Qtz"},"source":["Now let's plot the function $f(x) = x^{2} - x + 3$  for the given values of X"]},{"cell_type":"code","metadata":{"id":"JZ_5xJTR1m9h"},"source":["# Plotting x and y values\n","plt.plot(X, Y, marker='o',color='b',linestyle='-');\n","plt.plot(X, Y, 'o', color='r');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lp5no7O9A0zI"},"source":["## Gradient Descent\n","\n","It is an iterative optimization algorithm that finds the minimum value of a function. In this function the minimum value occurs at X = 0.5\n","\n"]},{"cell_type":"markdown","metadata":{"id":"9MGhWQICrK4h"},"source":["### How to converge the gradient ?\n","\n","* Where to start ?\n","\n","* In which direction to move?\n","\n","* How to reach the minimum point?\n","\n","\n","The general idea is to start with a random starting point X, the Gradient of a function gives always the direction of greatest rate of increase, and move towards the negative direction which minimizes the value of the function.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"DdTIiiflH6iX"},"source":["### The steps of the Gradient Descent algorithm\n","\n","1. Compute the gradient of the function (first order derivative of the function)\n","\n","2. Start from the random point by choosing learning rate ($\\eta$) and the no.of iterations\n","\n","3. Update the gradient and move towards negative slope to reach the minimum point.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hMUYPmgSSNlh"},"source":["The **learning rate ($\\eta$)** is a parameter which  influences the convergence of the algorithm. Larger learning rates make the algorithm take huge steps down the slope and it might jump across the minimum point thereby missing it. A low learning rate is more precise but calculating the gradient is time-consuming\n"]},{"cell_type":"code","source":["def f_prime(x1):\n","  var = np.poly1d([1,-1,3])\n","  derivative = var.deriv()\n","  f_derivative = derivative(x1)\n","  return f_derivative"],"metadata":{"id":"QDwOGPdczsBx"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"11-C1DsL1-io"},"source":["# Below is the function to converge the gradient\n","def gradient_converge(eta , gradient_x, iterations):\n","  for i in range(0,iterations):\n","\n","      # The derivative is the rate of change or the slope of a function at a given point\n","      deriv_x = f_prime(gradient_x)\n","      # Calculating the gradient_x = x - eta * f'(x)\n","      gradient_x = gradient_x - eta * deriv_x\n","\n","  return gradient_x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DEw2JGD91TBd"},"source":["Set the parameters for the gradient converge with iterations = 200, eta = 0.001"]},{"cell_type":"code","metadata":{"id":"2nYtA_Dr0-xo"},"source":["# Specify the number of iterations for the process to repeat.\n","iterations = 200\n","\n","# Set an initial value, to start with\n","Initial_point = 6\n","\n","# Learning rate\n","eta = 0.001"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SeXO4jUM1GRq"},"source":["# Calling the gradient_converge() function\n","gradient_x = gradient_converge(eta, Initial_point, iterations)\n","print(\"iterations = \",iterations,\"\\ngradient_x = \",gradient_x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v3U-9ge4sMDX"},"source":["Visualization of the Gradient Convergence for the above parameters"]},{"cell_type":"code","metadata":{"id":"-jvqRt6Tq31f"},"source":["plt.plot(X, Y, marker='o',color='b',linestyle='-');\n","plt.plot(X, Y, 'o', color='r');\n","y_gradient = func(gradient_x)\n","plt.plot(gradient_x, y_gradient,'ko',  markersize = 10)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c-dzU8Nu-Nv0"},"source":["From the above graph, with iterations = 200, eta = 0.001 the gradient has moved down to point 4, which is not the minimum point."]},{"cell_type":"markdown","metadata":{"id":"u-6ystdJ9BPk"},"source":["Now let's try changing the parameters for the gradient converge with, iterations = 9000, eta = 0.001"]},{"cell_type":"code","metadata":{"id":"dysw7KeH9BPu"},"source":["# Change the no.of iterations to 9000\n","iterations = 9000\n","\n","# Start point\n","Initial_point = 6\n","\n","# Learning rate\n","eta = 0.001\n","\n","# Calling the gradient_converge() function\n","gradient_x = gradient_converge(eta, Initial_point, iterations)\n","print(\"iterations = \",iterations,\"\\ngradient_x = \",gradient_x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eVmIPLWc97tE"},"source":["Visualize the Gradient Convergence for the changed parameters"]},{"cell_type":"code","metadata":{"id":"nL9OP4pq9fpk"},"source":["plt.plot(X, Y, marker='o',color='b',linestyle='-');\n","plt.plot(X, Y, 'o', color='r');\n","y_gradient = func(gradient_x)\n","plt.plot(gradient_x, y_gradient,'ko',  markersize = 10)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3gb6jKI6Br1M"},"source":["From the above graph, observe that after 9000 iterations the gradient reaches the minimum point in the plot which is very close to 0.5"]},{"cell_type":"markdown","metadata":{"id":"4YlpByIaDqcf"},"source":["Also try with learning rate ($\\eta$) = 0.01 and observe how the gradient converges quickly within 1000 iteration and reaches the minimum point"]},{"cell_type":"markdown","metadata":{"id":"tC2rt1ZxrgC7"},"source":["## Please answer the questions below to complete the experiment:"]},{"cell_type":"code","metadata":{"id":"NMzKSbLIgFzQ"},"source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"Good and Challenging for me\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pke4SQ5NgNFX"},"source":["#@title If it was very easy, what more you would have liked to have been added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"sdgfdjhfgjfhjh\" #@param {type:\"string\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_cTetkuegP7d"},"source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"Yes\" #@param [\"\",\"Yes\", \"No\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QFQw0ddId_Ej"},"source":["#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Comments = \"Somewhat Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-CXztFuygSBG","cellView":"form"},"source":["#@title Run this cell to submit your notebook  { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id =return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":null,"outputs":[]}]}