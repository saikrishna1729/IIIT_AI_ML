{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"HjrYIpy2yYbI"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint\n","\n"]},{"cell_type":"markdown","metadata":{"id":"x77SzRGJcY3o"},"source":["## Learning Objectives"]},{"cell_type":"markdown","metadata":{"id":"UKB4OmrMccgl"},"source":["At the end of the experiment,  you will be able to :\n","\n","* Understand how to derive Eigen faces using PCA\n","* Use the PCA features for classification purpose."]},{"cell_type":"code","metadata":{"id":"YGXM1QVJnGcI","cellView":"form"},"source":["#@title Experiment Walkthrough Video\n","\n","from IPython.display import HTML\n","HTML(\"\"\"<video width=\"854\" height=\"480\" controls>\n","<source src=\"https://cdn.talentsprint.com/talentsprint1/archives/sc/aiml/aiml_2018_b7_hyd/experiment_details_backup/pca_with_eigen_faces.mp4\" type=\"video/mp4\">\n","</video>\"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nFEZUAvJdXcW"},"source":["\n","\n","## Dataset"]},{"cell_type":"markdown","metadata":{"id":"_reikMZBdZ0o"},"source":["### Description\n","\n","The dataset chosen for this experiment is a preprocessed excerpt of the “Labeled Faces in the Wild”, aka LFW.\n","\n","Labeled Faces in the Wild, a database of face photographs designed for studying the problem of unconstrained face recognition. The data set contains more than 13,000 images of faces collected from the web. Each face has been labeled with the name of the person pictured. 1680 of the people pictured have two or more distinct photos in the data set. The only constraint on these faces is that they were detected by the Viola-Jones face detector."]},{"cell_type":"markdown","metadata":{"id":"RlGNyzR5fsxQ"},"source":["## AI / ML Technique"]},{"cell_type":"markdown","metadata":{"id":"Vy4vk5Fdfwg3"},"source":["### Eigen Faces\n","\n","Eigenfaces is the name given to a set of eigenvectors when they are used in the computer vision problem of human face recognition. The approach of using eigenfaces for recognition was developed by Sirovich and Kirby (1987) and used by Matthew Turk and Alex Pentland in face classification. The eigenvectors are derived from the covariance matrix of the probability distribution over the high-dimensional vector space of face images. The eigenfaces themselves form a basis set of all images used to construct the covariance matrix. This produces dimension reduction by allowing the smaller set of basis images to represent the original training images. Classification can be achieved by comparing how faces are represented by the basis set."]},{"cell_type":"markdown","metadata":{"id":"CGdoLqkdFmDm"},"source":["### Setup Steps:"]},{"cell_type":"code","metadata":{"id":"ylAsMmtoFmDq"},"source":["#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n","Id = \"\" #@param {type:\"string\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SHIYfAU8FmDr"},"source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"\" #@param {type:\"string\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WBPPuGmBlDIN","cellView":"form"},"source":["#@title Run this cell to complete the setup for this Notebook\n","from IPython import get_ipython\n","import re\n","ipython = get_ipython()\n","\n","notebook= \"U2W7_28_PCAwithEigenFaces_B\" #name of the notebook\n","\n","def setup():\n","    # ipython.magic(\"sx pip3 install torch\")\n","    from IPython.display import HTML, display\n","    ipython.magic(\"sx wget -qq https://cdn.talentsprint.com/aiml/Experiment_related_data/week1/Exp1/AIML_DS_REGR01_SIMPLEPENDULUMOSCILLATIONDATA.txt\")\n","    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n","    print(\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","\n","    import requests, json, base64, datetime\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:\n","        print(r[\"err\"])\n","        return None\n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getWalkthrough() and getComments() and getMentorSupport():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n","              \"concepts\" : Concepts, \"record_id\" : submission_id,\n","              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n","              \"notebook\" : notebook, \"feedback_walkthrough\":Walkthrough ,\n","              \"feedback_experiments_input\" : Comments,\n","              \"feedback_inclass_mentor\": Mentor_support}\n","\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","      if \"err\" in r:\n","        print(r[\"err\"])\n","        return None\n","      else:\n","        print(\"Your submission is successful.\")\n","        print(\"Ref Id:\", submission_id)\n","        print(\"Date of submission: \", r[\"date\"])\n","        print(\"Time of submission: \", r[\"time\"])\n","        print(\"View your submissions: https://learn-iiith.talentsprint.com/notebook_submissions\")\n","        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n","        return submission_id\n","    else: submission_id\n","\n","\n","def getAdditional():\n","  try:\n","    if not Additional:\n","      raise NameError\n","    else:\n","      return Additional\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    if not Complexity:\n","      raise NameError\n","    else:\n","      return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","\n","def getConcepts():\n","  try:\n","    if not Concepts:\n","      raise NameError\n","    else:\n","      return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","\n","def getWalkthrough():\n","  try:\n","    if not Walkthrough:\n","      raise NameError\n","    else:\n","      return Walkthrough\n","  except NameError:\n","    print (\"Please answer Walkthrough Question\")\n","    return None\n","\n","def getComments():\n","  try:\n","    if not Comments:\n","      raise NameError\n","    else:\n","      return Comments\n","  except NameError:\n","    print (\"Please answer Comments Question\")\n","    return None\n","\n","\n","def getMentorSupport():\n","  try:\n","    if not Mentor_support:\n","      raise NameError\n","    else:\n","      return Mentor_support\n","  except NameError:\n","    print (\"Please answer Mentor support Question\")\n","    return None\n","\n","def getAnswer():\n","  try:\n","    if not Answer:\n","      raise NameError\n","    else:\n","      return Answer\n","  except NameError:\n","    print (\"Please answer Question\")\n","    return None\n","\n","\n","def getId():\n","  try:\n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup\n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_R_HrXRcyYbL"},"source":["## Importing Required Packages"]},{"cell_type":"code","metadata":{"id":"BBg8NqofzFy3"},"source":["from time import time\n","import matplotlib.pyplot as plt\n","\n","# Importing Sklearn Packages\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import fetch_lfw_people\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.decomposition import PCA\n","from sklearn.metrics import accuracy_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q1C0XKy5nXKU"},"source":["## Download the data\n","\n","Load the Labeled Faces in the Wild (LFW) people dataset, To know more about LFW people dataset refer [link](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html)"]},{"cell_type":"code","metadata":{"id":"QXiT39fhnXKW"},"source":["# IF THIS CODE CELL GIVES ERROR THEN CONTINUE WITH THE NEXT CELLS\n","\n","# Loading and Downloading data from sklearn\n","lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n","\n","# Storing images arrays shapes (for plotting)\n","n_samples, h, w = lfw_people.images.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget https://ndownloader.figshare.com/files/5976015 -O lfw.tgz\n","!tar -xvzf lfw.tgz"],"metadata":{"id":"nqVGo4nanXKX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W5IPxeRqnXKX"},"source":["### Downloading LFW Dataset from an Alternative Source\n","\n","Since the default download link for `fetch_lfw_people` is currently unavailable (HTTP Error 403: Forbidden), we will manually download the `lfw-funneled.tgz` file from a known alternative source and extract it. Then, we will instruct `sklearn.datasets.fetch_lfw_people` to load the data from this local path."]},{"cell_type":"code","source":["%%capture\n","# Manually downloading the dataset\n","!mkdir lfw_home\n","!cd lfw_home && mkdir lfw_home\n","!gdown https://drive.google.com/uc?id=1XJdUomqTr8ZbQOYdmhbYdmtncc0JBjHJ\n","!unzip lfw-people-dataset.zip -d lfw_home/lfw_home/\n","!tar -xvzf /content/lfw_home/lfw_home/lfw-funneled.tgz -C lfw_home/lfw_home/"],"metadata":{"id":"jSzBQOYZU2lq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.datasets import fetch_lfw_people\n","\n","lfw_people = fetch_lfw_people(\n","    data_home=\"/content/lfw_home\",\n","    download_if_missing=False,\n","    min_faces_per_person=70,\n","    resize=0.4\n",")\n","\n","# Storing images arrays shapes (for plotting)\n","n_samples, h, w = lfw_people.images.shape\n","\n","n_samples, h, w"],"metadata":{"id":"n-6dTEF0Q18Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tVhrdxTtnXKZ"},"source":["`lfw_poeple` provides various attributes, where in `lfw_people.images` is the features of 3-dimensional shape and `lfw_people.data` holds the same information of images which is flattened array of images (1-dimensional array)"]},{"cell_type":"markdown","source":["### If above options do not work then manually download the dataset from [here](https://www.kaggle.com/datasets/atulanandjha/lfwpeople)"],"metadata":{"id":"SWhx3CN-nXKZ"}},{"cell_type":"markdown","metadata":{"id":"I9-dYGItJ_ex"},"source":["## Assigning lfw_people data to the X variable, by using the 'data' attribute."]},{"cell_type":"code","metadata":{"id":"hrC0ewCmzMx4"},"source":["X = lfw_people.data\n","\n","# Below will take 2nd value from X.shape\n","n_features = X.shape[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Aq5O4SJjzXpi"},"source":["# The label is the id of the person\n","y = lfw_people.target\n","# Loading the target names (Label names)\n","target_names = lfw_people.target_names\n","# Checkinq How many classes are present\n","n_classes = target_names.shape[0]\n","\n","print(\"Target names:\", target_names)\n","print(\"Total dataset size:\")\n","print(\"n_samples: %d\" % n_samples)\n","print(\"n_features: %d\" % n_features)\n","print(\"n_classes: %d\" % n_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fxkbeTCsKRm0"},"source":["## Split into a training and testing set using train_test_split sklearn function\n"]},{"cell_type":"code","metadata":{"id":"TU7bRT6WKQ8m"},"source":["X_train, X_test, y_train, y_test = # YOUR CODE HERE: To split the data into train and test sets"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1-fb1HraKiHU"},"source":["## Performing PCA on the face images, otherwise known as Eigenfaces"]},{"cell_type":"markdown","metadata":{"id":"Z-gecKLweD7_"},"source":["## Compute the PCA\n","\n","In PCA, a parameter Whiten = True, will remove some information from the transformed signal (the relative variance scales of the components) but can sometime improve the predictive accuracy of the downstream estimators by making their data respect some hard-wired assumptions.\n","\n","Whitening just makes our resulting data have a unit variance, which has been shown to produce better results"]},{"cell_type":"code","metadata":{"id":"ZIbummkGzYH6"},"source":["# Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n","# dataset): unsupervised feature extraction / dimensionality reduction\n","n_components = 150\n","\n","print(\"Extracting the top %d eigenfaces from %d faces\"\n","      % (n_components, X_train.shape[0]))\n","# Starting the timer\n","t0 = time()\n","\n","# Trying to extarct PCA features using PCA function from sklearn\n","pca = PCA(n_components=n_components, whiten=True).fit(X_train)\n","\n","# Printing the time taken to extract the features\n","print(\"done in %0.3fs\" % (time() - t0))\n","\n","# Storing the eigen faces\n","eigenfaces = pca.components_.reshape((n_components, h, w))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qi0IQ1-nIIOk"},"source":["## Projecting the input data on the eigenfaces orthonormal basis\n"]},{"cell_type":"code","metadata":{"id":"hRHdK40Fzcg6"},"source":["t0 = time()\n","# Transforming the data\n","X_train_pca = pca.transform(X_train)\n","X_test_pca = pca.transform(X_test)\n","print(\"done in %0.3fs\" % (time() - t0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4OKjxIaLzfZP"},"source":["# Checking for the shape of the original and pca  data\n","X_train.shape, X_train_pca.shape, X_test.shape, X_test_pca.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kzp9u2jdISz7"},"source":["## Train a Linear Classifier"]},{"cell_type":"markdown","metadata":{"id":"kBD2USvfIapC"},"source":["## Fitting the classifier to the training set"]},{"cell_type":"code","metadata":{"id":"IJCSYo1QYgAA"},"source":["t0 = time()\n","\n","from sklearn.linear_model import SGDClassifier\n","clf = SGDClassifier()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wCvUHd9_zjCo"},"source":["# Fit the data\n","clf = clf.fit(X_train_pca, y_train)\n","print(\"done in %0.3fs\" % (time() - t0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i486kOGEImdO"},"source":["##  Quantitative evaluation of the model quality on the test set"]},{"cell_type":"code","metadata":{"id":"bUfrCIQazr5_"},"source":["print(\"Predicting people's names on the test set\")\n","t0 = time()\n","y_pred = clf.predict(X_test_pca)\n","\n","from sklearn.metrics import accuracy_score\n","\n","print(\"done in %0.3fs\" % (time() - t0))\n","\n","# YOUR CODE HERE: To print the accuracy score\n","\n","print(\"classification report\")\n","# YOUR CODE HERE: Use Sklearn's 'classification_report' method and pass appropriate parameters to the same, and print the output here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s-JReJZd8taB"},"source":["## Qualitative evaluation of the predictions using matplotlib\n","\n","Below function `plot_gallery()` takes images, titles , height, width and plots each image in subplot\n"]},{"cell_type":"code","metadata":{"id":"ya44ZmAEzsX5"},"source":["def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n","    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n","    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n","    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n","    for i in range(n_row * n_col):\n","        plt.subplot(n_row, n_col, i + 1)\n","        # YOUR CODE HERE: Use plt.imshow image to show a gray scale image for the images in 'images' argument passed above.\n","        plt.title(titles[i], size=12)\n","        plt.xticks(())\n","        plt.yticks(())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8SMZsuqasWVR"},"source":["Below get_Title() function is to extract target names for predictions and actual values to plot along with images"]},{"cell_type":"code","source":["# Getting the last name of each target name\n","def get_Title(y_pred, y_test, target_names, i):\n","    pred_name = target_names[y_pred[i]].split(' ')[-1]\n","    true_name = target_names[y_test[i]].split(' ')[-1]\n","    return 'predicted: %s\\ntrue: %s' % (pred_name, true_name)"],"metadata":{"id":"ufJPFXmK_HqI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the prediction and actual titles and store in a list\n","prediction_titles = []\n","for i in range(y_pred.shape[0]):\n","  title =  get_Title(y_pred, y_test, target_names, i)\n","  prediction_titles.append(title)\n","\n","# Plot the result of the prediction on a portion of the test set\n","plot_gallery(X_test, prediction_titles, h, w, n_row=5, n_col= 2)"],"metadata":{"id":"6iVieHa-_J4F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kc5In04SL-8f"},"source":["## Plotting the eigen faces"]},{"cell_type":"code","source":["# Plot the gallery of the most significative eigenfaces\n","eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n","plot_gallery(eigenfaces, eigenface_titles, h, w)"],"metadata":{"id":"MgsZx58p_TOt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VHfHdGCP_n6Y"},"source":["### Please answer the questions below to complete the experiment:\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"kmvdJ4aNmGjR"},"source":["#@title State True or False: The dataset LFW, contains a set of EigenFaces which we use to train our Machine Learning model? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Answer = \"True\" #@param [\"\",\"True\",\"False\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sJ6Y8DkRGZkF"},"source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"Too Simple, I am wasting time\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"clKRj7eGGZkG"},"source":["#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"ald you have liked to be added? If it was very difficult, what would you hs too easy, w what more woul\" #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VBk_4VTAxCM"},"source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"No\" #@param [\"\",\"Yes\", \"No\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r35isHfTVGKc"},"source":["#@title  Experiment walkthrough video? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Walkthrough = \"Not Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XH91cL1JWH7m"},"source":["#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Comments = \"Didn't use\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8xLqj7VWIKW"},"source":["#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Mentor_support = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FzAZHt1zw-Y-","cellView":"form"},"source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id = return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":null,"outputs":[]}]}