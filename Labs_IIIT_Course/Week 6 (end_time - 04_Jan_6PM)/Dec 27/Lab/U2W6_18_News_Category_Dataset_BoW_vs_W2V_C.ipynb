{"cells":[{"cell_type":"markdown","metadata":{"id":"_uklj8Zuh9Fv"},"source":["\n","# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint\n","\n"]},{"cell_type":"markdown","metadata":{"id":"koiIre6cUWv_"},"source":["## Learning Objective"]},{"cell_type":"markdown","metadata":{"id":"OzkHDYHGZnyC"},"source":["\n","At the end of the experiment, you will be able to:\n","\n","*  Pre-process the data\n","*  Representation of  text document using Bag of Words & Word2Vec"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"XnIT_27v5ORu"},"outputs":[],"source":["#@title Experiment Walkthrough Video\n","#@markdown BoW vs W2V\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"854\" height=\"480\" controls>\n","  <source src=\"https://cdn.exec.talentsprint.com/non-processed/Bag_of_Words_Vs_Word2Vec.mp4\">\n","</video>\n","\"\"\")"]},{"cell_type":"markdown","metadata":{"id":"2RPrPQi532cK"},"source":["## Dataset"]},{"cell_type":"markdown","metadata":{"id":"snBfzAFAkIFA"},"source":["   This dataset contains around 200k news headlines from the year 2012 to 2018 obtained from [HuffPost](https://www.huffpost.com/). The model trained on this dataset could be used to identify tags for untracked news articles or to identify the type of language used in different news articles.\n","\n","Each news headline has a corresponding category. Categories and corresponding article counts as follows:\n","\n","\n","    POLITICS: 32739\n","    WELLNESS: 17827\n","    ENTERTAINMENT: 16058\n","    TRAVEL: 9887\n","    STYLE & BEAUTY: 9649\n","    PARENTING: 8677\n","    HEALTHY LIVING: 6694\n","    QUEER VOICES: 6314\n","    FOOD & DRINK: 6226\n","    BUSINESS: 5937\n","    COMEDY: 5175\n","    SPORTS: 4884\n","    BLACK VOICES: 4528\n","    HOME & LIVING: 4195\n","    PARENTS: 3955\n","    THE WORLDPOST: 3664\n","    WEDDINGS: 3651\n","    WOMEN: 3490\n","    IMPACT: 3459\n","    DIVORCE: 3426\n","    CRIME: 3405\n","    MEDIA: 2815\n","    WEIRD NEWS: 2670\n","    GREEN: 2622\n","    WORLDPOST: 2579\n","    RELIGION: 2556\n","    STYLE: 2254\n","    SCIENCE: 2178\n","    WORLD NEWS: 2177\n","    TASTE: 2096\n","    TECH: 2082\n","    MONEY: 1707\n","    ARTS: 1509\n","    FIFTY: 1401\n","    GOOD NEWS: 1398\n","    ARTS & CULTURE: 1339\n","    ENVIRONMENT: 1323\n","    COLLEGE: 1144\n","    LATINO VOICES: 1129\n","    CULTURE & ARTS: 1030\n","    EDUCATION: 1004\n","\n","\n","#### Description\n","This dataset has the following columns:\n","1. **Category:** Category article belongs to\n","2. **Headline:** Determines the Headline of the article\n","3. **Authors:** Person authored the article\n","4. **Link:** Link to the post\n","5. **Short_description:** Short description of the article\n","6. **Date:** Date the article was published\n","\n","Out of 41 category's from the News_Category_Dataset, we consider four category's (Travel, Tech, Science, College) for this experiment"]},{"cell_type":"markdown","metadata":{"id":"CGdoLqkdFmDm"},"source":["### Setup Steps:"]},{"cell_type":"code","metadata":{"id":"2YzfoPvJDiTX"},"source":["#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n","Id = \"\" #@param {type:\"string\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rEzlYL4CDrmE"},"source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"\" #@param {type:\"string\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WBPPuGmBlDIN","cellView":"form"},"source":["#@title Run this cell to complete the setup for this Notebook\n","from IPython import get_ipython\n","import re\n","ipython = get_ipython()\n","\n","notebook= \"U2W6_18_News_Category_Dataset_BoW_vs_W2V_C\" #name of the notebook\n","\n","def setup():\n","#  ipython.magic(\"sx pip3 install torch\")\n","    from IPython.display import HTML, display\n","    ipython.magic(\"sx wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/News_Category_Dataset_v2.csv\")\n","    ipython.magic(\"sx wget https://cdn.talentsprint.com/talentsprint1/archives/sc/aiml/experiment_related_data/AIML_DS_GOOGLENEWS-VECTORS-NEGATIVE-300_STD.rar\")\n","    ipython.magic(\"sx unrar e /content/AIML_DS_GOOGLENEWS-VECTORS-NEGATIVE-300_STD.rar\")\n","    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n","    print(\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","\n","    import requests, json, base64, datetime\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:\n","        print(r[\"err\"])\n","        return None\n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getWalkthrough() and getComments() and getMentorSupport():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n","              \"concepts\" : Concepts, \"record_id\" : submission_id,\n","              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n","              \"notebook\" : notebook, \"feedback_walkthrough\":Walkthrough ,\n","              \"feedback_experiments_input\" : Comments,\n","              \"feedback_inclass_mentor\": Mentor_support}\n","\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","      if \"err\" in r:\n","        print(r[\"err\"])\n","        return None\n","      else:\n","        print(\"Your submission is successful.\")\n","        print(\"Ref Id:\", submission_id)\n","        print(\"Date of submission: \", r[\"date\"])\n","        print(\"Time of submission: \", r[\"time\"])\n","        print(\"View your submissions: https://learn-iiith.talentsprint.com/notebook_submissions\")\n","        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n","        return submission_id\n","    else: submission_id\n","\n","\n","def getAdditional():\n","  try:\n","    if not Additional:\n","      raise NameError\n","    else:\n","      return Additional\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    if not Complexity:\n","      raise NameError\n","    else:\n","      return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","\n","def getConcepts():\n","  try:\n","    if not Concepts:\n","      raise NameError\n","    else:\n","      return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","\n","def getWalkthrough():\n","  try:\n","    if not Walkthrough:\n","      raise NameError\n","    else:\n","      return Walkthrough\n","  except NameError:\n","    print (\"Please answer Walkthrough Question\")\n","    return None\n","\n","def getComments():\n","  try:\n","    if not Comments:\n","      raise NameError\n","    else:\n","      return Comments\n","  except NameError:\n","    print (\"Please answer Comments Question\")\n","    return None\n","\n","\n","def getMentorSupport():\n","  try:\n","    if not Mentor_support:\n","      raise NameError\n","    else:\n","      return Mentor_support\n","  except NameError:\n","    print (\"Please answer Mentor support Question\")\n","    return None\n","\n","def getAnswer():\n","  try:\n","    if not Answer:\n","      raise NameError\n","    else:\n","      return Answer\n","  except NameError:\n","    print (\"Please answer Question\")\n","    return None\n","\n","\n","def getId():\n","  try:\n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup\n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2a9XmVH8dXjK"},"source":["## Import packages\n"]},{"cell_type":"code","source":["!pip3 install gensim"],"metadata":{"id":"QjlqyagYEqGP"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"53Heccvsee6Y"},"outputs":[],"source":["import re\n","import nltk\n","import pandas as pd\n","import numpy as np\n","import gensim\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"id":"oxW_xSfK4tjH"},"source":["## Load the data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JM4mgpFwpws3"},"outputs":[],"source":["# Load the data\n","df = pd.read_csv('News_Category_Dataset_v2.csv')\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wu0ax7S5b6RS"},"outputs":[],"source":["# Count the classes in category\n","df['category'].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"KPTGmXsF82J2"},"source":["## Data Pre-processing"]},{"cell_type":"markdown","metadata":{"id":"UiyOvedV5Rsl"},"source":["we are considering four category's (Travel, Tech, Science, College) for this experiment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lyg6RjTpbmJt"},"outputs":[],"source":["# Create a list of manually selected category\n","category = ['TRAVEL','TECH','SCIENCE','COLLEGE']\n","\n","# Load the dataset based on the category\n","df = df[df['category'].isin(category)]      # .isin whether each element in the DataFrame is contained in values.\n","df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lx1oxkqKa-Tu"},"outputs":[],"source":["# Add the two columns into text column\n","df['text'] = df['headline'] +','+ df['short_description']\n","df['label'] = df['category']"]},{"cell_type":"markdown","metadata":{"id":"CudtuGFW6Pzp"},"source":["Drop the unwanted columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X6o41T2x6OH0"},"outputs":[],"source":["df = df.drop(['headline','short_description','date','authors','link','category','Unnamed: 0'], axis=1)\n","df.shape"]},{"cell_type":"markdown","metadata":{"id":"oF0X1nch6Zar"},"source":["Consider text column as feature and label as target variable. Convert label into numerical.\n","\n","Hint: Label Encoder for obtaining a numeric representation, refer to the [link](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2xEm4MdXjAeM"},"outputs":[],"source":["from sklearn import preprocessing\n","le = preprocessing.LabelEncoder()\n","df['label']=le.fit_transform(df['label'])\n","df['label'].head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EeMg8HEZc1ID"},"outputs":[],"source":["df['text'].shape, df['label'].shape"]},{"cell_type":"code","source":["df['text']"],"metadata":{"id":"HJgFGf1oTHbD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4hmWpDAtMnj_"},"source":["## BoW"]},{"cell_type":"markdown","metadata":{"id":"YQr_afHnUcTL"},"source":["### TF IDF\n"," tf-idf aims to represent the number of times a given word appears in a document (a movie review in our case) relative to the number of documents in the corpus that the word appears in â€” where, words that appear in many documents have a value closer to zero and words that appear in less documents have values closer to 1.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y3WF846nxGTS"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","tfidf_vectorizer = TfidfVectorizer()\n","alltext = df['text'].astype(str)\n","tfidf_feature = tfidf_vectorizer.fit_transform(alltext)"]},{"cell_type":"markdown","metadata":{"id":"qBwRCxlVM1Ch"},"source":["### Split the data into train and test sets\n","\n","Hint: Refer to[Train-Test split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-yTNLOj9hIR8"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test,y_train,y_test = train_test_split(tfidf_feature,df['label'],test_size = 0.2,random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"Sg3MwoH2M477"},"source":["### Apply the Classification\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fArIDcoGgv3E"},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.svm import SVC\n","\n","# Create an object for all the algorithms\n","model1 = DecisionTreeClassifier()\n","model2 = KNeighborsClassifier(n_neighbors=8)\n","model3 = SGDClassifier()\n","model4 = SVC(kernel='linear')\n","\n","models = [model1, model2, model3, model4]\n","\n","for model in models:\n","    model.fit(X_train, y_train)         # fit the model\n","    y_pred= model.predict(X_test)       # then predict on the test set\n","    accuracy= accuracy_score(y_test, y_pred)\n","    print(\"Accuracy (in %):\", model, \"is\", accuracy)\n"]},{"cell_type":"markdown","metadata":{"id":"Gq4fYQQ8Yids"},"source":["## Word2Vec"]},{"cell_type":"markdown","metadata":{"id":"Lvhba-_oNx8l"},"source":["###Load pre-trained Word2Vec\n","\n","Lets now proceed to load the complete pretrained vectors."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tNxU0Jc10YqO"},"outputs":[],"source":["W2Vmodel = gensim.models.KeyedVectors.load_word2vec_format('AIML_DS_GOOGLENEWS-VECTORS-NEGATIVE-300_STD.bin', binary=True, limit=500000)"]},{"cell_type":"markdown","metadata":{"id":"wFdjtmZLDTqq"},"source":["### Word2Vec representation\n","\n","Convert each document into average of the word2vec vectors of all valid words in document"]},{"cell_type":"markdown","metadata":{"id":"3PQVzVad8eN3"},"source":["Note: Below code cell take some time to compile"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B0iv1RAYzhtE"},"outputs":[],"source":["# Creating empty final dataframe\n","docs_vectors = pd.DataFrame()\n","\n","# Removing stop words\n","stopwords = nltk.corpus.stopwords.words('english')\n","text = df['text'].astype(str)\n","# Looping through each document and cleaning it\n","for doc in text.str.lower().str.replace('[^a-z ]', ''):\n","    temp = pd.DataFrame()\n","    for word in doc.split(' '):\n","        # If word is not present in stopwords then (try)\n","        if word not in stopwords and word.isalpha():\n","            try:\n","                # If word is present in embeddings then get the vector representation and append it to temporary dataframe\n","                word_vec = W2Vmodel[word]\n","                temp = temp._append(pd.Series(word_vec), ignore_index = True)\n","\n","            except:\n","                pass\n","    # Take the average of vectors for each word\n","    doc_vector = temp.mean()\n","    # Append each document value to the final dataframe\n","    docs_vectors = docs_vectors._append(doc_vector, ignore_index = True)\n","docs_vectors.shape\n","\n"]},{"cell_type":"markdown","metadata":{"id":"k2FR6SQv-TqC"},"source":["### Split the data into train and test sets\n","\n","Hint: Refer to[Train-Test split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1EikyJ9qcj3P"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test,y_train,y_test = train_test_split(docs_vectors,df['label'],test_size = 0.2,random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"oWTFS1oa8Xlf"},"source":["### Apply the Classification\n"]},{"cell_type":"code","source":["from sklearn.impute import SimpleImputer\n","imputer = SimpleImputer(strategy=\"mean\")\n","X_train_imputed = imputer.fit_transform(X_train)\n","X_test_imputed = imputer.transform(X_test)"],"metadata":{"id":"TzxLk2cPWnmB"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z994GRolBMrH"},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.svm import SVC\n","\n","# Create an object for all the algorithms\n","model1 = DecisionTreeClassifier()\n","model2 = KNeighborsClassifier(n_neighbors=8)\n","model3 = SGDClassifier()\n","model4 = SVC(kernel='linear')\n","\n","models = [model1, model2, model3, model4]\n","\n","for model in models:\n","    model.fit(X_train_imputed, y_train)         # fit the model\n","    y_pred= model.predict(X_test_imputed)       # then predict on the test set\n","    accuracy= accuracy_score(y_test, y_pred)\n","    print(\"Accuracy(in %):\", model, \"is\", accuracy)"]},{"cell_type":"markdown","metadata":{"id":"VHfHdGCP_n6Y"},"source":["### Please answer the questions below to complete the experiment:\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"kmvdJ4aNmGjR"},"source":["#@title What is the difference between word2vec and BOW? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Answer = \"\" #@param [\"\",\"Word2vec produces one vector per word whereas BoW produces one number that is a word count\",\"Word2vec produces one  number that is a word count whereas BoW produces one vector per word\"]\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sJ6Y8DkRGZkF"},"source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"clKRj7eGGZkG"},"source":["#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"\" #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VBk_4VTAxCM"},"source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r35isHfTVGKc"},"source":["#@title  Experiment walkthrough video? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Walkthrough = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XH91cL1JWH7m"},"source":["#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8xLqj7VWIKW"},"source":["#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FzAZHt1zw-Y-","cellView":"form"},"source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id = return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}