{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"-uKoHMMJ0iOE"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint\n"]},{"cell_type":"markdown","metadata":{"id":"c-9LguthAIGs"},"source":["### Objective\n","\n","- To understand several techniques in Text representation"]},{"cell_type":"code","metadata":{"id":"ftfEjck9eqp4","cellView":"form"},"source":["#@title Experiment Walkthrough Video\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"900\" height=\"400\" controls>\n","  <source src=\"https://cdn.exec.talentsprint.com/content/Text_representation.mp4\" type=\"video/mp4\">\n","</video>\n","\"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"snBfzAFAkIFA"},"source":["### Dataset\n","   Here we will be using Movies_review data which contains 50000 reviews. The training data and testing are split evenly, 25k reviews under reviews_train and 25k under reviews_test.\n","Under each file first 12500 reviews are positive and remaining 12500 are negative reviews.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CGdoLqkdFmDm"},"source":["### Setup Steps:"]},{"cell_type":"code","metadata":{"id":"2YzfoPvJDiTX"},"source":["#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n","Id = \"\" #@param {type:\"string\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rEzlYL4CDrmE"},"source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"\" #@param {type:\"string\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WBPPuGmBlDIN"},"source":["#@title Run this cell to complete the setup for this Notebook\n","from IPython import get_ipython\n","import re\n","ipython = get_ipython()\n","\n","notebook= \"U1W4_17_Text_representation_using_Sckit_learn_B\" #name of the notebook\n","\n","def setup():\n","#  ipython.magic(\"sx pip3 install torch\")\n","    from IPython.display import HTML, display\n","    ipython.magic(\"sx wget -qq https://cdn.talentsprint.com/aiml/movie_data.tar.gz\")\n","    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n","    print(\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","\n","    import requests, json, base64, datetime\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:\n","        print(r[\"err\"])\n","        return None\n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getWalkthrough() and getComments() and getMentorSupport():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n","              \"concepts\" : Concepts, \"record_id\" : submission_id,\n","              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n","              \"notebook\" : notebook, \"feedback_walkthrough\":Walkthrough ,\n","              \"feedback_experiments_input\" : Comments,\n","              \"feedback_inclass_mentor\": Mentor_support}\n","\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","      if \"err\" in r:\n","        print(r[\"err\"])\n","        return None\n","      else:\n","        print(\"Your submission is successful.\")\n","        print(\"Ref Id:\", submission_id)\n","        print(\"Date of submission: \", r[\"date\"])\n","        print(\"Time of submission: \", r[\"time\"])\n","        print(\"View your submissions: https://learn-iiith.talentsprint.com/notebook_submissions\")\n","        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n","        return submission_id\n","    else: submission_id\n","\n","\n","def getAdditional():\n","  try:\n","    if not Additional:\n","      raise NameError\n","    else:\n","      return Additional\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    if not Complexity:\n","      raise NameError\n","    else:\n","      return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","\n","def getConcepts():\n","  try:\n","    if not Concepts:\n","      raise NameError\n","    else:\n","      return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","\n","def getWalkthrough():\n","  try:\n","    if not Walkthrough:\n","      raise NameError\n","    else:\n","      return Walkthrough\n","  except NameError:\n","    print (\"Please answer Walkthrough Question\")\n","    return None\n","\n","def getComments():\n","  try:\n","    if not Comments:\n","      raise NameError\n","    else:\n","      return Comments\n","  except NameError:\n","    print (\"Please answer Comments Question\")\n","    return None\n","\n","\n","def getMentorSupport():\n","  try:\n","    if not Mentor_support:\n","      raise NameError\n","    else:\n","      return Mentor_support\n","  except NameError:\n","    print (\"Please answer Mentor support Question\")\n","    return None\n","\n","def getAnswer():\n","  try:\n","    if not Answer:\n","      raise NameError\n","    else:\n","      return Answer\n","  except NameError:\n","    print (\"Please answer Question\")\n","    return None\n","\n","\n","def getId():\n","  try:\n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup\n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Extarct data"],"metadata":{"id":"A2Gdm0f0915i"}},{"cell_type":"code","metadata":{"id":"qBgMzy4jAxbU"},"source":["# Extract the files from the downloaded folder\n","import tarfile\n","my_tar = tarfile.open(\"movie_data.tar.gz\")  # Open the tarfile\n","my_tar.extractall(\"/content/\")          # Specify the folder and extract the files in the Specified folder\n","my_tar.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GYUL2aOrfPm0"},"source":["### Importing required packages\n"]},{"cell_type":"code","metadata":{"id":"LsXb4LeA8qPA"},"source":["import numpy as np\n","import pandas as pd\n","import os\n","import re\n","from sklearn.metrics import accuracy_score\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KZv8zJIt8zy4"},"source":["# Read each line and append to a list\n","reviews_train = []\n","\n","for line in open(\"/content/movie_data/full_train.txt\", \"r\"):\n","    reviews_train.append(line.strip())\n","\n","reviews_test = []\n","\n","for line in open(\"/content/movie_data/full_test.txt\", \"r\"):\n","    reviews_test.append(line.strip())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xBZqzPqR8_md"},"source":["# Read the 20000th review from train text file\n","reviews_train[19999]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ekBGXYC2_S-8"},"source":["Replace_without_space = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")    # All these characters in text will be removed\n","Replace_with_space = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")            # All these characters in text will be replaced by space\n","NO_SPACE = \"\"\n","SPACE = \" \"\n","\n","def preprocess_reviews(reviews):\n","    reviews = [Replace_without_space.sub(NO_SPACE, line.lower()) for line in reviews]\n","    reviews = [Replace_with_space.sub(SPACE, line) for line in reviews]\n","    return np.array(reviews)\n","\n","reviews_train_clean = preprocess_reviews(reviews_train)\n","reviews_test_clean = preprocess_reviews(reviews_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0O_3LXcs_of2"},"source":["# Verify the 20000th review from train text file\n","reviews_train_clean[19999]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GCbUX25rDkD0"},"source":["Give labels for the movie reviews, where first 12500 reviews are positive and remaining 12500 are negative reviews."]},{"cell_type":"code","metadata":{"id":"RVNZvV2oy7FD"},"source":["target = np.array([1 if i < 12500 else 0 for i in range(25000)])  # Labeling positive reviews as 1 and negative reviews as 0\n","print(target.shape, target[345], target[20000])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S9MnDcKliORP"},"source":["### CountVectorizer\n"]},{"cell_type":"markdown","metadata":{"id":"oiz7XKrmQ9l3"},"source":["Using N-grams get the consecutive words from the given text and get the feature vector using the countvectorizer for the same."]},{"cell_type":"code","metadata":{"id":"p4ocUqUv_sLf"},"source":["\"\"\"To get binary values (1 for present or 0 for absent) instead of counts of terms/tokens, give binary=True.\n","N-Gram range basically lets you decide the length of the sequence of consecutive words in the given text. Suppose the n-gram range = (1, 3).\n","Then it will pick the unigram(only single word), bigram (group of 2 consecutive words), and the trigram (group of 3 consecutive words).\"\"\"\n","\n","ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n","ngram_vectorizer.fit(reviews_train_clean)                         # Tokenize and build vocab\n","train_vec = # YOUR CODE HERE: To tranfsorm get feature vector for train data\n","test_vec = # YOUR CODE HERE: To transform and get feature vector for test data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YeEuYxynkBtn"},"source":["#### Split the review_train data into train and test sets\n","\n","Hint: Refer to[Train-Test split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"]},{"cell_type":"code","metadata":{"id":"u7kCsHWMkA-M"},"source":["# Split the train and test sets\n","X_train,X_test, y_train,y_test = # YOUR CODE HERE: To split the train and test data with 75-25%"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TmJ2nArFtiBB"},"source":["X_train.shape, X_test.shape, y_train.shape, y_test.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qpfOG53zlz5S"},"source":["#### Apply the Decision Tree Classifier for the splitted review_train data\n","Note: Below code cell take some time to compile"]},{"cell_type":"code","metadata":{"id":"jm7QJlvEDMSk"},"source":["# Create an object for the DecisionTreeClassifier\n","decisiontree = DecisionTreeClassifier()\n","\n","# Fit the model and get the predictions\n","decisiontree.fit(X_train,y_train)\n","\n","# Predict the model\n","predict = decisiontree.predict(X_test)\n","\n","# Calculate the accuracy\n","accuracy_score(y_test, predict)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XDfY6Q9ODNNn"},"source":["# Use the trained model to get the predictions on the review_test data\n","predict = decisiontree.predict(test_vec)\n","accuracy_score(target, predict)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YQr_afHnUcTL"},"source":["### TF IDF\n"," tf-idf aims to represent the number of times a given word appears in a document (a movie review in our case) relative to the number of documents in the corpus that the word appears in â€” where, words that appear in many documents have a value closer to zero and words that appear in less documents have values closer to 1.\n","\n","We have seen how to get the consecutive words using n-grams, similarly you can try without using n-grams\n"]},{"cell_type":"code","metadata":{"id":"_x75doewBlY-"},"source":["tfidf_vectorizer = TfidfVectorizer()\n","tfidf_vectorizer.fit(reviews_train_clean)\n","X_train_tfidf = # YOUR CODE HERE: To transform and get feature vector for train data\n","X_test_tfidf = # YOUR CODE HERE: To transform and get feature vector for test data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GXQcZ_plKMDh"},"source":["#### Split the review_train data into train and test sets\n","\n","Hint: Refer to [Train-Test split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"]},{"cell_type":"code","metadata":{"id":"pgjZaKTUKMDm"},"source":["# Split the train and test sets\n","X1_train, X1_test, y1_train, y1_test = # YOUR CODE HERE: To split the train and test data with 75-25%"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lZwW_AFZxlXt"},"source":["\n","#### Apply the Decision Tree Classifier\n","Note: Below code cell take some time to complie"]},{"cell_type":"code","metadata":{"id":"E1vkXQEExlXx"},"source":["# Create an object of DecisionTreeClassifier\n","decisiontree = DecisionTreeClassifier()\n","\n","# Fit the model and get the predictions\n","decisiontree.fit(X1_train,y1_train)\n","\n","# Predict the model\n","predict = decisiontree.predict(X1_test)\n","\n","# Calculate the accuracy\n","accuracy_score(y1_test, predict)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DYwelCgQxlYK"},"source":["# Use the trained model to get the predictions on the review_test data\n","predict = decisiontree.predict(X_test_tfidf)\n","accuracy_score(target, predict)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VHfHdGCP_n6Y"},"source":["### Please answer the questions below to complete the experiment:\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"kmvdJ4aNmGjR"},"source":["#@title Using N-grams for: Sentence representation, Word prediction (auto-complete), Ambiguity resolution (Speech recognition, OCR), Machine Translation (choosing one sentence over another). { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Answer = \"\" #@param [\"\",\"TRUE\", \"FALSE\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sJ6Y8DkRGZkF"},"source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"clKRj7eGGZkG"},"source":["#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"\" #@param {type:\"string\"}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VBk_4VTAxCM"},"source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r35isHfTVGKc"},"source":["#@title  Experiment walkthrough video? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Walkthrough = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XH91cL1JWH7m"},"source":["#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8xLqj7VWIKW"},"source":["#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FzAZHt1zw-Y-","cellView":"form"},"source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id = return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":null,"outputs":[]}]}